%! TeX root = ../../main.tex

\chapter{Derivations}

\section{Fourier transform of the retarded correlator}
\label{app:fourier-transform}

Fourier transform of the retarded correlator from time to frequency space.
\begin{align}
    C_z
     & =
    \mathcal{F}[-\mi \Theta(t) \langle \{A(t), B\}\rangle] \\
     & =
    \mathcal{F}[-\mi \Theta(t) \langle A(t) B\rangle]
    +
    \mathcal{F}[-\mi \Theta(t) \langle B A(t)\rangle]      \\
     & =
    C^+_z + C^-_z
\end{align}
Transformation of the first component:
\begin{align}
    C^+_z
     & =
    \int_{-\infty}^\infty \md t \>
    \me^{\mi zt}(-\mi \Theta(t) \langle \me^{\mi Ht} A \me^{-\mi Ht} B\rangle)     \\
     & =
    -\mi \int_0^\infty \md t \>
    \me^{\mi zt} \langle \me^{\mi Ht} A \me^{-\mi Ht} B\rangle                     \\
     & =
    -\mi \int_0^\infty \md t \>
    \me^{\mi zt} \langle \me^{\mi E_0t} A \me^{-\mi Ht} B\rangle                   \\
     & =
    -\mi \int_0^\infty \md t \>
    \langle A \me^{\mi(z - H + E_0)t} B\rangle                                     \\
     & =
    -\mi \left.\left\langle A \frac{\me^{\mi(z - H + E_0)t}}{\mi(z - H + E_0)} B\right\rangle
    \right|_0^\infty                                                               \\
     & =
    -\mi \left(0 - \left\langle A \frac{1}{\mi(z - H + E_0)} B\right\rangle\right) \\
     & =
    \left\langle A \frac{1}{z - H + E_0} B\right\rangle
\end{align}
Transformation of the second component:
\begin{align}
    C^-_z
     & =
    \int_{-\infty}^\infty \md t \>
    \me^{\mi zt}(-\mi \Theta(t) \langle B \me^{\mi Ht} A \me^{-\mi Ht}\rangle) \\
     & =
    -\mi \int_0^\infty \md t \>
    \me^{\mi zt} \langle B \me^{\mi Ht} A \me^{-\mi Ht}\rangle                 \\
     & =
    -\mi \int_0^\infty \md t \>
    \me^{\mi zt} \langle B \me^{\mi Ht} A \me^{-\mi E_0t}\rangle               \\
     & =
    -\mi \int_0^\infty \md t \>
    \langle B \me^{\mi(z + H - E_0)t} A\rangle                                 \\
     & =
    \left\langle B \frac{1}{z + H - E_0} A\right\rangle
\end{align}

\chapter{Tridiagonalization of a symmetric impurity Green's function}

Proof that the diagonal entries vanish when a symmetric impurity Green's function
is represented as a continued fraction.

The impurity solver returns the Green's function as a sum of poles
\begin{align}
    \mathcal{G}_{\!\omega} = \sum_{i=1}^N \frac{b_i^2}{\omega - a_i}.
    \label{eq:impurity-greens-function}
\end{align}
Symmetry enforces that each location appears pairwise $\pm a_i$
with the same weight $b_i^2$.
This in turn sets all moments for odd $m$ to zero
% TODO: explain moment
\begin{align}
    M^{(m)}_{\mathcal{G}}
     & \coloneqq
    \sum_i a_i^m b_i^2                                     \\
     & =
    \sum_{a_i>0} a_i^m b_i^2 + \sum_{a_i<0} a_i^m b_i^2    \\
     & =
    \sum_{a_i>0} a_i^m b_i^2 + \sum_{a_i>0} (-a_i)^m b_i^2 \\
     & =
    \sum_{a_i>0} a_i^m b_i^2 - \sum_{a_i>0} a_i^m b_i^2    \\
     & =
    0.
\end{align}
\todo{Should I mention that it's inside the appendix?}
In \cite[appendix B]{Lu2014}, \citeauthor{Lu2014} showed how to transform
\zcref{eq:impurity-greens-function} into a continued fraction representation
using the Lanczos algorithm on the diagonal matrix
\begin{equation}
    A
    =
    \diag(a_1, a_2, \ldots, a_N)
\end{equation}
and starting vector
\begin{equation}
    \vec{v}_1 = (b_1, b_2, \ldots, b_N)^\intercal.
\end{equation}

We can prove our statement by showing that the $i$-th component ($i \in \{1, \ldots, N\}$)
of the $j$-th Lanczos vector
can be written as a weighted sum
of separated even/odd powers of the original locations $a_i$
\begin{align}
    (\vec{v}_1)_i
     & = b_i                              \\
    (\vec{v}_2)_i
     & = b_i c_{2,1} a_i                  \\
    (\vec{v}_3)_i
     & = b_i ( c_{3,2}a_i^2 + c_{3,0})    \\
    (\vec{v}_4)_i
     & = b_i ( c_{4,3}a_i^3 + c_{4,1}a_i) \\
    (\vec{v}_j)_i
     & =
    b_i\sum\limits_{k=0}^{\lfloor j/2\rfloor}
    \begin{cases}
        c_{j,2k+1} a_i^{2k+1}, & j \text{ even} \\
        c_{j,2k} a_i^{2k},     & j \text{ odd}.
    \end{cases}
    \label{eq:statement-tridiagonalization}
\end{align}
Here, the coefficient $c_{j,l}$ is associated with the $j$-th Lanczos vector
and $l$-th power in $a$.
They are not particularly relevant for the derivation and are only kept to guarantee
orthonormality of the Lanczos vectors.
For the base case ($j=1$) we can verify the statement by setting $c_{1,0}=1$
\begin{equation}
    (\vec{v}_1)_i
    =
    b_i\!\sum\limits_{k=0}^{0} c_{1,2k} a_i^{2k}
    =
    b_i c_{1,0} a_i^0
    =
    b_i.
\end{equation}
For the induction step we first calculate the new vector
\begin{align}
    (\vec{u}_{j+1})_i
     & =
    (A \vec{v}_j - \beta_{j-1}\vec{v}_{j-1})_i \\
     & =
    b_i
    \left(
    \sum\limits_k
    \begin{cases}
        c_{j,2k+1} a_i^{2k+2} \\
        c_{j,2k} a_i^{2k+1}
    \end{cases}
    - \beta_{j-1}
    \sum\limits_l
    \begin{cases}
        c_{j-1,2l} a_i^{2l} \\
        c_{j-1,2l+1} a_i^{2l+1}
    \end{cases}
    \right)
\end{align}
For the second term we can do an index shift $l \rightarrow k+1$
in order to collect the same powers of $a_i$
\begin{equation}
    (\vec{u}_{j+1})_i
    =
    b_i
    \sum\limits_k
    \begin{cases}
        (c_{j,2k+1} - \beta_{j-1} c_{j-1,2k+2}) a_i^{2k+2}, & j \text{ even} \\
        (c_{j,2k} - \beta_{j-1} c_{j-1,2l+3}) a_i^{2k+1},   & j \text{ odd}.
    \end{cases}.
\end{equation}
This means that this new vector $\vec{u}_j$ still has the form of separated even/odd powers
as in the statement (\zcref{eq:statement-tridiagonalization}).
The Lanczos coefficient $\alpha_j$ is given by the overlap
\begin{equation}
    \alpha_j
    =
    \vec{v}_j^\dagger A \vec{v}_i
    =
    \vec{v}_j^\dagger \vec{u}_{j+1}.
\end{equation}
If the case of even $j$, odd powers of $a_i$ (given by $\vec{v}_j$)
are multiplied by even powers of $a_i$ (given by $\vec{u}_j$)
(for odd $j$ vice versa).
Hence, the inner product only contains a sum of odd powers $a_i$ which all vanish
(diagonal $\alpha_j = 0$)
and Lanczos vectors never couple to their predecessor
keeping even and odd powers of $a_i$ separated.

\section{Eigenvalues}

The tridiagonal matrix is thus given by
\begin{equation}
    T
    =
    \begin{pmatrix}
        0       & \beta_1 &         &             &             \\
        \beta_1 & 0       & \beta_2 &             &             \\
                & \beta_2 & 0       & \ddots      &             \\
                &         & \ddots  & \ddots      & \beta_{N-1} \\
                &         &         & \beta_{N-1} & 0
    \end{pmatrix}.
\end{equation}
We can define a unitary matrix
\begin{equation}
    L = \diag(1, -1, 1, -1, \ldots)
\end{equation}
with the property $L T L = -T$.
Applying it to the eigenvalue equation gives
\begin{align}
    L(T \vec{v}   & = \lambda \vec{v})    \\
    LT LL\vec{v}  & = \lambda L\vec{v}    \\
    -T (L\vec{v}) & = \lambda (L\vec{v})  \\
    T (L\vec{v})  & = -\lambda (L\vec{v})
\end{align}
proving that each eigenvalue appears pairwise $\pm\lambda$.
This is precisely the statement with which we started:
Each pole location appears pairwise $\pm a_i$ with the same weight $b_i^2$.
